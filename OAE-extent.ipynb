{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bdb0e87-14a7-41b4-81cc-bca0f3cdb242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install all necessary packages\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "from cmcrameri import cm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from collections import OrderedDict\n",
    "from matplotlib.lines import Line2D  \n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from cartopy.io import shapereader\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "from netCDF4 import Dataset as NetCDFFile \n",
    "import matplotlib.patches as mpatches\n",
    "import cmocean\n",
    "from scipy.interpolate import griddata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5f52ad-789d-4bc5-997c-09a79c4bca44",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CODE FROM HERE BASED ON CODE EXAMPLES BY DR ANDREW MERDITH FROM EARTHBYTE GROUP ###\n",
    "# Andrew's rotation data files \n",
    "rot_file = './Andrew_data/'\n",
    "topology_features = [rot_file+'MER21/250-0_plate_boundaries_Merdith_et_al.gpml',\n",
    "                     rot_file+'MER21/410-250_plate_boundaries_Merdith_et_al.gpml',\n",
    "                     rot_file+'MER21/TopologyBuildingBlocks_Merdith_et_al.gpml',\n",
    "                     rot_file+'MER21/1000-410-Convergence_Merdith_et_al.gpml',\n",
    "                     rot_file+'MER21/1000-410-Divergence_Merdith_et_al.gpml',\n",
    "                     rot_file+'MER21/1000-410-Topologies_Merdith_et_al.gpml',\n",
    "                     rot_file+'MER21/1000-410-Transforms_Merdith_et_al.gpml']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb8255a-6255-4c2a-9664-b10ec09df197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding rotation files into collection for pygplates\n",
    "static_polygons = pygplates.FeatureCollection(\n",
    "    rot_file+'MER21/shapes_static_polygons_Merdith_et_al.gpml')\n",
    "polygons = pygplates.FeatureCollection(\n",
    "    rot_file+'MER21/Global_EarthByte_GeeK07_COB_Terranes_ContinentsOnly_MER21_edits.gpml')\n",
    "rotation_model = pygplates.RotationModel(rot_file+'MER21/1000_0_rotfile_Merdith_et_al.rot')\n",
    "coastlines = pygplates.FeatureCollection(\n",
    "    rot_file+'MER21/shapes_continents_Merdith_et_al.gpml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5f6c7e-a4f6-4132-afc8-b9dc533ba890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gplately model using above files\n",
    "model = gplately.PlateReconstruction(\n",
    "    rotation_model, topology_features, coastlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d522a0-65a5-4b97-ba4c-d0e720493cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make present-day plot of points\n",
    "gPlot = gplately.plot.PlotTopologies(model, coastlines=coastlines, COBs=polygons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae23d54-9391-4351-8319-b502e6d5f6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data to be reconstructed (modern lats and lons to paleo lats and lons)\n",
    "# Currently has my original data file in (i.e. before I replaced lats and lons with recon_lats and recon_lons in the excel file)\n",
    "filtered_data = pd.read_csv(\"Toarcian_data_thisone_final_final_final.csv\")\n",
    "filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79474e0-55e4-4edf-afcc-3264022e8581",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(filtered_data.columns)\n",
    "recon_lons= \n",
    "recon_lats= "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fbfc6c-f076-41f4-a517-1f9ed64c85c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute geometry as points (we will turn into polygons next) and convert to geopandas\n",
    "filtered_data['geometry'] = filtered_data.apply(lambda row: pygplates.PointOnSphere(float(row.lat),\n",
    "                                                              float(row.lon)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b804c84-88a8-4169-80bf-178fb6d63aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#group our entries by their index so we can find which ones are lines and not points\n",
    "for ind, (name, group) in enumerate(filtered_data.groupby('Site number')): \n",
    "\n",
    "    #print(ind, len(group))\n",
    "    #line has more than 1 entry\n",
    "    if len(group) > 1:\n",
    "        \n",
    "        test = group\n",
    "        \n",
    "        polyLine = pygplates.PolylineOnSphere(group['geometry'])\n",
    "        filtered_data.at[group.index[0], 'geometry'] = polyLine\n",
    "        #drop second row now we no longer need it\n",
    "        filtered_data.drop([group.index[1]], inplace=True)\n",
    "#reset index\n",
    "filtered_data.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcc460d-c2d3-4fe7-a7af-ddc6e454548f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pygplates.PointOnSphere(float(group.lat), float(group.lon))\n",
    "filtered_data.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df9070d-c35b-4fb4-9dd8-8fe184d74900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through list of poles and produce GPML file of multiple VGPs.\n",
    "geometry = []\n",
    "plantCountry = []\n",
    "plantArea = []\n",
    "plantFunction = []\n",
    "plantLowerAge = []\n",
    "plantUpperAge = []\n",
    "plantgeometry=[]\n",
    "plantEnv=[]\n",
    "plantID=[]\n",
    "\n",
    "for i in np.arange(0, len(filtered_data)):\n",
    "       \n",
    "    geometry.append(filtered_data.geometry[i])\n",
    "    if filtered_data['Area'][i] is np.nan:\n",
    "        plantCountry.append(filtered_data.Area[i])\n",
    "        plantFunction.append(filtered_data['Site number'][i])\n",
    "    else:\n",
    "        plantCountry.append((filtered_data['Area'][i], filtered_data.Area[i]))\n",
    "        plantFunction.append(filtered_data['Site number'][i])\n",
    "        plantEnv.append(filtered_data['Redox interpretation'][i])\n",
    "        plantID.append(filtered_data['Study site'][i])\n",
    "    plantLowerAge.append(int(600))\n",
    "    plantUpperAge.append(int(0))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d85145-6e99-44e0-a0fb-70dd4220484d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create new GPlates Feature Collection\n",
    "plantFeatureCollection = pygplates.FeatureCollection()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d284995-3f4c-4bc4-93b1-b01e8f05178e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#assign data to feature\n",
    "for j in np.arange(0, len(filtered_data)):\n",
    "    plantFeature = pygplates.Feature.create_reconstructable_feature(\n",
    "        pygplates.FeatureType.gpml_unclassified_feature,\n",
    "        geometry[j],\n",
    "        name = str(plantID[j]),\n",
    "        valid_time=(float(plantLowerAge[j]), float(plantUpperAge[j])))\n",
    "    # Add newly created feature to existing Feature Collection\n",
    "  #  plantFeatureCollection.add(plantFeature)\n",
    "    {'Function' : str(plantFunction[j])}\n",
    "    # Add newly created feature to existing Feature Collection\n",
    "    plantFeatureCollection.add(plantFeature)\n",
    "#note: a lot of import errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fb6d12-26e9-4f2e-902b-1493ffd352e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign plate ids\n",
    "# Create new GPlates Feature Collection\n",
    "plate_partitioner = pygplates.PlatePartitioner(coastlines, rotation_model)\n",
    "partitioned_plant_features = plate_partitioner.partition_features(\n",
    "                                        plantFeatureCollection,\n",
    "                                        partition_method = pygplates.PartitionMethod.most_overlapping_plate)\n",
    "\n",
    "plantFeatureCollection = pygplates.FeatureCollection(partitioned_plant_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca0c23d-e780-4db8-b4b1-9a85c0c76b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "gPlot.time = 183 \n",
    "phanerozoic_data = plantFeatureCollection\n",
    "\n",
    "reconstructed_data = model.reconstruct(phanerozoic_data, gPlot.time)\n",
    "\n",
    "recon_lons = []\n",
    "recon_lats = []\n",
    "env = []\n",
    "for ind, i in enumerate(reconstructed_data):\n",
    "    recon_lons.append(i.get_reconstructed_geometry().to_lat_lon()[1])\n",
    "    recon_lats.append(i.get_reconstructed_geometry().to_lat_lon()[0])\n",
    "    env.append(i.get_feature().get_name())\n",
    "\n",
    "all_env_codes = np.asarray(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec209f15-04e7-4bec-b013-5f012574fbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export lat/lon and land code\n",
    "with open(\"TOAE_data.csv\", 'w', newline='') as file:\n",
    "    writer = csv.writer(file, dialect='excel')\n",
    "    writer.writerow(recon_lons)\n",
    "    writer.writerow(recon_lats)\n",
    "    writer.writerow(all_env_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6555af-b690-49d1-b140-a88c8504d46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print length of reconstructed data \n",
    "len(reconstructed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf06f236-881f-4db5-948a-e676befed826",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['pdf.fonttype'] = 42\n",
    "mpl.rcParams['font.sans-serif'] = \"Tahoma\"\n",
    "\n",
    "fig = plt.figure(figsize=(18,12))\n",
    "ax = fig.add_subplot(111, projection=ccrs.Robinson(central_longitude=0))\n",
    "\n",
    "#gPlot.plot_continents(ax, facecolor='0.8')\n",
    "gPlot.plot_coastlines(ax, color='0.85')\n",
    "gPlot.plot_ridges_and_transforms(ax, lw=1, alpha=0.5, color='#545EB3')\n",
    "gPlot.plot_trenches(ax, lw=1, color='#853a2b')\n",
    "gPlot.plot_misc_boundaries(ax, lw=0.5, color='k')\n",
    "gPlot.plot_subduction_teeth(ax, color='#853a2b')\n",
    "\n",
    "ax.scatter(recon_lons, recon_lats, transform=ccrs.Geodetic())\n",
    "\n",
    "lat_spacing = 30\n",
    "lon_spacing = 30\n",
    "ax.gridlines(\n",
    "    draw_labels=True,\n",
    "    ylocs=list(np.arange(-90, 90+lat_spacing, lat_spacing)),\n",
    "    xlocs=list(np.arange(-180,180+lon_spacing, lon_spacing)),\n",
    ")\n",
    "\n",
    "\n",
    "### CODE BASED ON CODE EXAMPLES BY DR ANDREW MERDITH FROM EARTHBYTE GROUP ENDS HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e132f6a-762d-4044-b317-6c2186238176",
   "metadata": {},
   "outputs": [],
   "source": [
    "### MY ORIGINAL CODE STARTS HERE ###\n",
    "# read csv\n",
    "data = pd.read_csv('Map40_185Ma.csv')  \n",
    "\n",
    "# lat, lon, elev\n",
    "lons = data['# lon']  \n",
    "lats = data['lat']   \n",
    "elevations = data['elev']  \n",
    "\n",
    "# make map\n",
    "fig = plt.figure(figsize=(9, 6))\n",
    "ax = fig.add_subplot(111, projection=ccrs.PlateCarree())\n",
    "\n",
    "# plot data\n",
    "sc = ax.scatter(lons, lats, c=elevations, cmap='viridis', s=10, transform=ccrs.PlateCarree())\n",
    "\n",
    "# colour bar\n",
    "plt.colorbar(sc, label='Elevation (m)')\n",
    "\n",
    "# plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8299ee13-03b3-4604-bfba-35db0de5f538",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading in same dataset but with elevations and recon_lats and recon_lons instead of modern lats and lons \n",
    "filtered_data = pd.read_csv(\"TOAE_lats_lons_elevations_final_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db19831-11e5-40a1-917d-0c8153c6b40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read nc file\n",
    "nc = NetCDFFile('./Scotese_Wright_2018_Maps_1-88_1degX1deg_PaleoDEMS_nc_v2/Map40_PALEOMAP_1deg_Early_Jurassic_185Ma.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c00dbaf-8606-4b95-b494-fc68d4e8def0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#view nc file\n",
    "print(nc.variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e8a0dd-768e-4491-a341-92d58870b899",
   "metadata": {},
   "outputs": [],
   "source": [
    "#assign variables- note you will have to re-run this cell every time you want to adjust the map, so I put this code in the top of that code as well \n",
    "lat = nc.variables['lat'][:]\n",
    "lon = nc.variables['lon'][:]\n",
    "z = nc.variables['z'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee577a05-e485-4bd9-8eea-637172ab2464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot and save elevation map and datapoints\n",
    "lat = nc.variables['lat'][:]\n",
    "lon = nc.variables['lon'][:]\n",
    "z = nc.variables['z'][:]\n",
    "\n",
    "data_lons = filtered_data['lon']\n",
    "data_lats = filtered_data['lat']\n",
    "\n",
    "recon_lons_a=np.array(data_lons)\n",
    "recon_lats_a=np.array(data_lats)\n",
    "\n",
    "#figure size and layout \n",
    "plt.figure(figsize=(20,10))\n",
    "plt.tight_layout()\n",
    "\n",
    "#plot contour \n",
    "plt.contourf(lon, lat, z, cmap=cmocean.cm.deep_r)\n",
    "colorbar= plt.colorbar()\n",
    "colorbar.set_label('Elevation (m)', fontsize= 14)\n",
    "\n",
    "#ensure axes on same scale\n",
    "plt.gca().set_aspect(\"equal\")\n",
    "\n",
    "#plot scatter points\n",
    "plt.scatter(recon_lons, recon_lats, color='red', marker='o')\n",
    "\n",
    "#organise scatter points by oxygen state \n",
    "labels= filtered_data['Redox interpretation']\n",
    "#label_colourmap = {label: color for label, color in zip(unique_labels,['red', 'blue', 'green', 'orange', 'purple', 'cyan', 'magenta', 'yellow', 'brown', 'pink'])}\n",
    "# Loop through each data point and plot based on its label\n",
    "for lon, lat, label in zip(data_lons, data_lats, labels):\n",
    "    if label == 'Euxinic ':\n",
    "        plt.scatter(lon, lat, color='maroon', marker='o') # Plot 'Oxic' points\n",
    "    elif label == 'Anoxic ':\n",
    "        plt.scatter(lon, lat, color='lightcoral', marker='o')\n",
    "    elif label == 'Anoxic':\n",
    "        plt.scatter(lon, lat, color='lightcoral', marker='o')\n",
    "    elif label == 'Suboxic ':\n",
    "        plt.scatter(lon, lat, color='darkorange', marker='o')\n",
    "    else:\n",
    "        print('youre missing one')\n",
    "\n",
    "\n",
    "#labels and title\n",
    "plt.xlabel('Longitude', fontsize= 14)\n",
    "plt.ylabel('Latitude', fontsize= 14)\n",
    "plt.title('Map of the Toarcian period with Sample Data Points', fontsize= 16)\n",
    "\n",
    "#legend \n",
    "Euxinic_patch = mpatches.Patch(color='maroon', label='Euxinic')\n",
    "Anoxic_patch = mpatches.Patch(color='lightcoral', label='Anoxic')\n",
    "Suboxic_patch = mpatches.Patch(color='darkorange', label='Suboxic')\n",
    "plt.legend(handles=[Euxinic_patch, Anoxic_patch, Suboxic_patch])\n",
    "\n",
    "plt.show \n",
    "plt.savefig('T-OAE_map_single')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8119f5-951d-4857-9229-eac7a4702f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract elevations for each datapoint (manually)\n",
    "\n",
    "def find_elevation_from_nc(recon_lats, recon_lons, lat, lon, z):\n",
    "     Create a meshgrid of the NC file coordinates\n",
    "    lon_mesh, lat_mesh = np.meshgrid(lon, lat)\n",
    "    \n",
    "# reshape coordinates and elevation data\n",
    "    points = np.column_stack((lat_mesh.flatten(), lon_mesh.flatten()))\n",
    "    values = z.flatten()\n",
    "    \n",
    "# create array of target points\n",
    "    xi = np.column_stack((recon_lats, recon_lons))\n",
    "    \n",
    "     Interpolate elevation values at the target points\n",
    "    elevation = griddata(points, values, xi, method='linear')\n",
    "    \n",
    "    return elevation\n",
    "\n",
    "target_points = [\n",
    "    (20.434572, 6.989361),\n",
    "    (38.961984, 25.387083),\n",
    "    (28.225464, 31.435073),\n",
    "    (34.029520, 26.528961),\n",
    "    (45.001242, 26.379404),\n",
    "    (27.162020, 27.901794),\n",
    "    (44.048547, 33.979269),\n",
    "    (31.586694, 25.435194),\n",
    "    (34.967497, 21.885426),\n",
    "    (37.419805, 27.925387),\n",
    "    (26.696380, 31.962176),\n",
    "    (37.536909, 27.877383),\n",
    "    (34.783539, 21.867301),\n",
    "    (41.117205, 20.589335),\n",
    "    (24.554648, 18.188033),\n",
    "    (36.638260, 27.831164),\n",
    "    (43.589623, 28.770044),\n",
    "    (36.486303, 25.355519),\n",
    "    (14.887676, 32.705544),\n",
    "    (26.022205, 32.081131),\n",
    "    (41.029868, 20.579030),\n",
    "    (23.394308, 14.877934),\n",
    "    (46.260636, 28.959611),\n",
    "    (36.995575, 16.079762),\n",
    "    (26.574802, 32.186236),\n",
    "    (43.488719, 33.480240),\n",
    "    (26.347982, 10.715752),\n",
    "    (19.169121, 31.075515),\n",
    "    (40.332396, 11.825718),\n",
    "    (19.439008, 10.240827),\n",
    "    (29.484933, 27.937313),\n",
    "    (37.375931, 27.999062),\n",
    "    (36.702567, 27.962623),\n",
    "    (31.732089, 26.745355),\n",
    "    (39.447970, 17.440738),\n",
    "    (32.489450, 27.602206),\n",
    "    (34.623117, 24.306109),\n",
    "    (41.543382, 26.152684),\n",
    "    (31.839077, 31.190986),\n",
    "    (32.045752, 26.424513),\n",
    "    (19.445471, 31.170446),\n",
    "    (23.677075, 28.795486),\n",
    "    (35.721142, 10.768188),\n",
    "    (45.887304, 13.598371),\n",
    "    (29.357023, 15.423959),\n",
    "    (35.863229, 18.666081),\n",
    "    (38.732988, 17.558699),\n",
    "    (42.368080, 34.326134),\n",
    "    (79.716302, -33.717361),\n",
    "    (79.804895, -56.401371),\n",
    "    (59.503112, 152.673563),\n",
    "    (30.151131, 112.918703),\n",
    "    (43.378243, 146.920745),\n",
    "    (52.029301, -170.247947),\n",
    "    (50.767596, -167.215695),\n",
    "    (52.362826, 139.474821),\n",
    "    (52.362826, 139.474821),\n",
    "    (-45.890991, -21.386685),\n",
    "    (3.869406, -35.624184),\n",
    "    (20.329999, -35.999739),\n",
    "    (32.534049, -39.460509),\n",
    "    (32.534049, -39.460509),\n",
    "    (-4.263128, -33.134764),\n",
    "    (39.774456, -55.479838),\n",
    "    (43.238519, 6.072109),\n",
    "    (32.753371, -17.126329)\n",
    "]\n",
    "\n",
    "# split the points into lat and lon arrays\n",
    "recon_lats = np.array([p[0] for p in target_points])\n",
    "recon_lons = np.array([p[1] for p in target_points])\n",
    "\n",
    "# extract elevations\n",
    "elevations = find_elevation_from_nc(recon_lats, recon_lons, lat, lon, z)\n",
    "\n",
    "# print results\n",
    "print(f\"{'Latitude':>12} {'Longitude':>12} {'Elevation':>12}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for point, elev in zip(target_points, elevations):\n",
    "    print(f\"{point[0]:12.4f} {point[1]:12.4f} {elev:12.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e32dfee-83da-453b-a29e-d209475e3484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create raster file from elevation values from nc file \n",
    "\n",
    "lat = nc.variables['lat'][:]\n",
    "lon = nc.variables['lon'][:]\n",
    "z = nc.variables['z'][:]\n",
    "\n",
    "z_anox= 1*z\n",
    "for i in np.arange (0, 181):\n",
    "    for j in np.arange (0, 361):\n",
    "        if z [i, j]< -2375 and z[i, j]> -3706: #change these variables \n",
    "            z_anox [i,j]= 1\n",
    "        else: \n",
    "            z_anox [i, j]= 0\n",
    "\n",
    "#plot contour \n",
    "plt.figure(figsize=(20,10))\n",
    "plt.contourf(lon, lat, z_anox)\n",
    "colorbar= plt.colorbar()\n",
    "colorbar.set_label('Elevation (m)', fontsize= 14)\n",
    "plt.gca().set_aspect(\"equal\")\n",
    "\n",
    "#for lon, lat, label in zip(data_lons, data_lats, labels):\n",
    " #   if label == 'Euxinic ':\n",
    "  #      plt.scatter(lon, lat, color='maroon', marker='o') # Plot 'Oxic' points\n",
    "   # elif label == 'Anoxic ':\n",
    "    #    plt.scatter(lon, lat, color='lightcoral', marker='o')\n",
    "  #  elif label == 'Anoxic':\n",
    "   #     plt.scatter(lon, lat, color='lightcoral', marker='o')\n",
    "    #elif label == 'Suboxic ':\n",
    "     #   plt.scatter(lon, lat, color='darkorange', marker='o')\n",
    "    #else:\n",
    "     #  print('youre missing one')\n",
    "\n",
    "print(z_anox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ceedcb-94dd-43de-8665-163e3149c3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid box area in km2 and total global area\n",
    "Re = 6371 ; #earth radius km\n",
    "delta_lat = 1 ; #model resolution lat\n",
    "delta_lon = 1 ; # model resolution lon\n",
    "dist_lat =  2* np.pi * Re * delta_lat / 360 ;\n",
    "dist_lon =  2* np.pi * Re * np.cos(np.deg2rad(lat)) * delta_lon/ 360 ;\n",
    "gridarea_vec = dist_lon * dist_lat ;\n",
    "gridarea = np.empty([181, 361]) ;\n",
    "\n",
    "#print(gridarea_vec.shape)\n",
    "#gridarea[:,0] = gridarea_vec\n",
    "for n in np.arange(0, 360):\n",
    "    gridarea[:,n] = gridarea_vec\n",
    "\n",
    "plt.imshow(gridarea)\n",
    "plt.colorbar()\n",
    "print(np.sum(gridarea))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54619bfd-4e04-4783-9c15-d9eee1847887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculation of maximal estimate (everywhere at specific elevation)\n",
    "anoxarea= np.sum(z_anox*gridarea)\n",
    "worldarea= np.sum(gridarea)\n",
    "anoxfrac= (anoxarea/worldarea)*100\n",
    "print(anoxfrac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907db753-365e-456d-af9c-d8ef372346ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert raster to csv for manual editing in excel (for conservative estimate)\n",
    "\n",
    "def raster_to_matrix_csv(z_anox, lat, lon, output_path):\n",
    "    # create dataFrame with z_anox values\n",
    "    # using latitude (rows) and longitude (columns) as index\n",
    "    df = pd.DataFrame(\n",
    "        data=z_anox,\n",
    "        index=lat,\n",
    "        columns=lon\n",
    "    )\n",
    "    \n",
    "    # add latitude label to index\n",
    "    df.index.name = 'Latitude'\n",
    "    \n",
    "    # export to CSV\n",
    "    df.to_csv(output_path)\n",
    "    print(f\"CSV file saved to: {output_path}\")\n",
    "    \n",
    "    # print shape information\n",
    "    print(\"\\nData Summary:\")\n",
    "    print(f\"Matrix shape: {z_anox.shape}\")\n",
    "    print(f\"Number of latitudes: {len(lat)}\")\n",
    "    print(f\"Number of longitudes: {len(lon)}\")\n",
    "\n",
    "# save file to computer \n",
    "output_path = 'z_anox_matrix_toae_95.csv'\n",
    "raster_to_matrix_csv(z_anox, lat, lon, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7278309a-907f-4c72-b601-58f8e703e0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load back in edited csv file \n",
    "conservative_data = pd.read_csv(\"z_anox_matrix_toae_95_edited.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224984dc-7b00-436d-adc7-aebc8ac04707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get longitude and latitude values\n",
    "lons = conservative_data.columns.astype(float)\n",
    "lats = conservative_data.index.astype(float)\n",
    "\n",
    "# create meshgrid for contourf\n",
    "lon_mesh, lat_mesh = np.meshgrid(lons, lats)\n",
    "\n",
    "# create the plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# plot using contourf using only 2 levels since data is binary\n",
    "contour = plt.contourf(lon_mesh, lat_mesh, conservative_data, \n",
    "                      levels=[-0.5, 0.5, 1.5],  \n",
    "                      colors=['purple', 'yellow'],  \n",
    "                      extend='neither')  \n",
    "plt.gca().set_aspect(\"equal\")\n",
    "\n",
    "# colourbar\n",
    "cbar = plt.colorbar(contour, ticks=[0, 1])\n",
    "cbar.set_label('Binary Value (0/1)')\n",
    "\n",
    "# labels and title \n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.title('Conservative estimate')\n",
    "\n",
    "# gridlines\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4a7434-2113-4590-acac-1a33d71aab73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define z and elevations (z) at which we expect anoxia \n",
    "z = nc.variables['z'][:]\n",
    "data = np.where(conservative_data == 1, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f981026b-2026-4f1e-9062-549ffb1c1a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculation of conservative estimate (where datapoints have coincided with area at that elevation)\n",
    "anoxarea= np.sum(data*gridarea)\n",
    "worldarea= np.sum(gridarea)\n",
    "anoxfrac= (anoxarea/worldarea)*100\n",
    "print(anoxfrac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b447f68e-e1b5-454b-a350-d01bf03dcb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creation of map of conservative estimate (can be edietd to create map of maximal estimate)\n",
    "\n",
    "lat = nc.variables['lat'][:]\n",
    "lon = nc.variables['lon'][:]\n",
    "z = nc.variables['z'][:]\n",
    "\n",
    "# create figure and axis\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.tight_layout()\n",
    "\n",
    "# main contour plot\n",
    "main_contour = plt.contourf(lon, lat, z, cmap=cmocean.cm.deep_r)\n",
    "colorbar = plt.colorbar()\n",
    "colorbar.set_label('Elevation (m)', fontsize=14)\n",
    "\n",
    "# create contour lines of the area\n",
    "#contour_lines = plt.contour(lon, lat, data, levels=[0], \n",
    " #                          colors='lightcoral', linewidths=1.5, \n",
    "  #                         linestyles='dashed')\n",
    "\n",
    "# add filled regions\n",
    "lon = lon[1:-1]\n",
    "lat = lat[::-1]\n",
    "data_95_array = data[:, 1:-1]  # i removed the first and last columns using numpy slicing due to my data not fitting \n",
    "contourf_regions = plt.contourf(lon, lat, data_95_array, \n",
    "                               levels=[0.5, 1.5],  \n",
    "                               colors=['lightcoral'],\n",
    "                               alpha=0.5,\n",
    "                               zorder=1)\n",
    "plt.gca().set_aspect(\"equal\")\n",
    "\n",
    "# plot scatter points by oxygen state\n",
    "for lon, lat, label in zip(data_lons, data_lats, labels):\n",
    "    if label == 'Euxinic ':\n",
    "        plt.scatter(lon, lat, color='maroon', marker='o') # Plot 'Oxic' points\n",
    "    elif label == 'Anoxic ':\n",
    "        plt.scatter(lon, lat, color='lightcoral', marker='o')\n",
    "    elif label == 'Anoxic':\n",
    "        plt.scatter(lon, lat, color='lightcoral', marker='o')\n",
    "    elif label == 'Suboxic ':\n",
    "        plt.scatter(lon, lat, color='darkorange', marker='o')\n",
    "    else:\n",
    "        print('youre missing one')\n",
    "\n",
    "# labels and title\n",
    "plt.xlabel('Longitude', fontsize=14)\n",
    "plt.ylabel('Latitude', fontsize=14)\n",
    "plt.title('Map of the Cenomanian/Turonian period with Sample Data Points and Maximal Estimate for the Extent of Anoxia', fontsize=16)\n",
    "\n",
    "# legend\n",
    "Anoxic_patch = mpatches.Patch(color='lightcoral', label='Anoxic')\n",
    "Suboxic_patch = mpatches.Patch(color='darkorange', label='Suboxic')\n",
    "Oxic_patch = mpatches.Patch(color='khaki', label='Oxic')\n",
    "z_anox_line = mpatches.Patch(facecolor='lightcoral', label='Maximal Extent of Anoxia', alpha=0.5)\n",
    "plt.legend(handles=[Anoxic_patch, Suboxic_patch, Oxic_patch, z_anox_line], loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:geo_env]",
   "language": "python",
   "name": "conda-env-geo_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
